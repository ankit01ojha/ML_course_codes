{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Loading dataset\n",
    "dataset = pd.read_csv('diabetes.csv')\n",
    "\n",
    "dataset.head(10)\n",
    "data = dataset.values\n",
    "print(len(data))\n",
    "#c\n",
    "train, test = data[:614], data[614:]\n",
    "print(len(train),len(test), len(data))\n",
    "#d\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X=data[:,0:8]\n",
    "Y=data[:,8]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)  \n",
    "            \n",
    "\n",
    "print( X_test)\n",
    "\n",
    "scaler=StandardScaler().fit(X_train)              \n",
    "X_train=scaler.transform(X_train)\n",
    "scaler=StandardScaler().fit(X_test)              \n",
    "X_test=scaler.transform(X_test) \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(n_neighbors=5)  \n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "#The output y_pred is a list of predictions for each sample in the test data. The samples have been categorised as 0 or 1\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Confusion matrix prints a matrix containing the details of predictions. In this case class 0 is taken as positive\n",
    "# and class 1 as negative. The matrix contains 4 entries TP, FP, FN, TN. TP means no of samples which were predicted \n",
    "# as 0 and are actually 0, FP means no of samples which were predicted as 0 but are actually 1, FN means no of samples  \n",
    "# which were predicted 1 and are actually 0 and TN means no of samples predicted 1 and actually 1.\n",
    "print(classification_report(y_test,y_pred))\n",
    "# Classification report calculates the precision, recall, f1 score(the harmonic mean of precision and recall) \n",
    "# and support is no of occurence of each class in y_test\n",
    "print(\"No of correct predictions = \",accuracy_score(y_test, y_pred)*len(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
